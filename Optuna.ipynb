{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-17 11:33:52,442] A new study created in memory with name: no-name-aa719f12-cde5-4de9-b145-03e19617d2eb\n",
      "[I 2024-09-17 11:33:52,476] Trial 0 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.01117316045925188, 'C': 0.8164449685394375}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,490] Trial 1 finished with value: 0.8070175438596491 and parameters: {'learning_rate': 0.00013772071225645247, 'C': 0.0003518301073700355}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,507] Trial 2 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 5.9704864078909555e-05, 'C': 0.014183330949101876}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,676] Trial 3 finished with value: 0.6228070175438597 and parameters: {'learning_rate': 3.212577654264932e-05, 'C': 4.808255069373159e-05}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,732] Trial 4 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.0029261375020419957, 'C': 0.00522077392819176}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,742] Trial 5 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.023617826652915532, 'C': 0.016181305270367295}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,758] Trial 6 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 9.036126259988659e-05, 'C': 0.013205914740146337}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2024-09-17 11:33:52,779] Trial 7 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.008006905143994053, 'C': 0.07777173914815366}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:52,810] Trial 8 finished with value: 0.956140350877193 and parameters: {'learning_rate': 0.005355622640537222, 'C': 0.003049610596907732}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:52,843] Trial 9 finished with value: 0.8947368421052632 and parameters: {'learning_rate': 1.6691343679814882e-05, 'C': 0.0011267816096593689}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:52,904] Trial 10 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.07567843230533966, 'C': 2.534305816438691}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:52,926] Trial 11 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.0007683076052882093, 'C': 0.6617998501933838}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:52,972] Trial 12 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.014965678660516311, 'C': 0.15833275712766703}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:52,998] Trial 13 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0014507563538767544, 'C': 0.1553561465703495}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,034] Trial 14 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.07550563906909626, 'C': 0.08104712153713468}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,088] Trial 15 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.0004392333673030616, 'C': 5.836729662636887}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,115] Trial 16 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.020337997459960455, 'C': 0.1294418941337946}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,153] Trial 17 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.006215339154039644, 'C': 0.055965109129330295}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,194] Trial 18 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.03145193327160934, 'C': 0.5453720608198818}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,241] Trial 19 finished with value: 0.6842105263157895 and parameters: {'learning_rate': 0.0021074955783406298, 'C': 0.0001405911512701416}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,278] Trial 20 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.00039927990754771325, 'C': 8.654245547390248}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,324] Trial 21 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0016143805542448973, 'C': 0.16582548226856747}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,350] Trial 22 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.005511084893459086, 'C': 0.2792334319946258}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,401] Trial 23 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.010921415689227524, 'C': 0.041094390298099394}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,439] Trial 24 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.0012665334254396143, 'C': 1.8680916867899808}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,467] Trial 25 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0035023772120756106, 'C': 0.04420246740406582}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,521] Trial 26 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.00024792342492260436, 'C': 0.2384184678651197}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,560] Trial 27 finished with value: 0.9122807017543859 and parameters: {'learning_rate': 0.010818134668437706, 'C': 0.0014637802877965022}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,589] Trial 28 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.0009418538887334669, 'C': 1.3727832701188492}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,646] Trial 29 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.03928082501130956, 'C': 0.4410132966061685}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,674] Trial 30 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.013388566679953418, 'C': 0.030049974034803625}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,714] Trial 31 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.03495287990495519, 'C': 0.0907932308045548}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,736] Trial 32 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.08920161082305282, 'C': 0.10083669877394387}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,774] Trial 33 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.05186446842790491, 'C': 0.006518666168586445}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,807] Trial 34 finished with value: 0.6228070175438597 and parameters: {'learning_rate': 0.015875670743104475, 'C': 1.0242114917752998e-05}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,842] Trial 35 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.008204897994041947, 'C': 0.019603061252771472}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,874] Trial 36 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.003007304477005066, 'C': 0.9942157599810654}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,907] Trial 37 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.057941162547464196, 'C': 0.07488309979880829}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,940] Trial 38 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.025094939633562796, 'C': 0.293766032968848}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,964] Trial 39 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.0034199627940440396, 'C': 0.008993618759560314}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:53,993] Trial 40 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.00016737962190424842, 'C': 0.02322455046760433}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,028] Trial 41 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.020145387116297757, 'C': 0.13925601001785937}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,064] Trial 42 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.09543608933829516, 'C': 0.1094402523785032}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,093] Trial 43 finished with value: 0.956140350877193 and parameters: {'learning_rate': 0.018219558800559386, 'C': 0.003448198633650771}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,132] Trial 44 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.05706397161093367, 'C': 3.2713218684344643}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,160] Trial 45 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.00781664697652714, 'C': 0.4032926445861166}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,200] Trial 46 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 3.6364402279896494e-05, 'C': 0.8334864654112046}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,226] Trial 47 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.031047742493066757, 'C': 0.18957475215273478}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,256] Trial 48 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.002234564064606475, 'C': 0.051695571219763266}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,292] Trial 49 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.005674058172779669, 'C': 0.012928840223536079}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,351] Trial 50 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.009299861256535865, 'C': 0.14284430618915853}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,376] Trial 51 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.004857402587074005, 'C': 0.05527236170287914}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,413] Trial 52 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0007276455677177782, 'C': 0.0342230033286124}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,441] Trial 53 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.015143672593162363, 'C': 0.07025997349176223}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,480] Trial 54 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0045328520726522345, 'C': 0.23780751407695233}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,509] Trial 55 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 1.013961300697821e-05, 'C': 0.46465052683093344}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,543] Trial 56 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.001742099204565967, 'C': 0.017528808820982157}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,575] Trial 57 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.023769419700254108, 'C': 0.035451058566653516}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,613] Trial 58 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.04180771211905914, 'C': 0.17253905040411227}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,642] Trial 59 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.006588590074627088, 'C': 0.6800014427348682}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,679] Trial 60 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0006205458273638107, 'C': 0.3190760371724021}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,707] Trial 61 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.001238265962587093, 'C': 0.0887612093315296}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,741] Trial 62 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0015914645345222879, 'C': 0.14973376580476572}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,769] Trial 63 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.011307667134448548, 'C': 0.06744624760272377}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,806] Trial 64 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.00041184289036662113, 'C': 0.027876299147401785}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,836] Trial 65 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.002561120571028077, 'C': 0.213326889244804}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:54,872] Trial 66 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.004154624450993672, 'C': 1.1536988015585496}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,010] Trial 67 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.012464982055916052, 'C': 0.010615871062047021}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,062] Trial 68 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.006690147837523334, 'C': 0.04487005858930922}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,087] Trial 69 finished with value: 0.7192982456140351 and parameters: {'learning_rate': 0.06344909996604621, 'C': 0.00018846557411259082}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,120] Trial 70 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.028300905783492, 'C': 1.8701241374647815}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,150] Trial 71 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.003833137034847378, 'C': 0.10069742219655138}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,180] Trial 72 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0010525581405068198, 'C': 0.3495109669433581}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,212] Trial 73 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.018096567751244897, 'C': 0.11895390429136428}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,249] Trial 74 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.009473026650424321, 'C': 0.6659434377370959}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,276] Trial 75 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0015484025097802874, 'C': 0.282256828375994}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,315] Trial 76 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.00028858233287390694, 'C': 0.19336385990679586}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,343] Trial 77 finished with value: 0.9736842105263158 and parameters: {'learning_rate': 0.04447673518720028, 'C': 0.5023756310494875}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,373] Trial 78 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.006313126567757068, 'C': 0.05685390851360933}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,407] Trial 79 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.002614987463899184, 'C': 0.02318001979923305}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,440] Trial 80 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.07799853905335002, 'C': 0.12412509955457539}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,468] Trial 81 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.008086276033072078, 'C': 0.07174066260399657}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,498] Trial 82 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.014421205200845536, 'C': 0.04214381963778189}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,531] Trial 83 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.01072838060471253, 'C': 0.006893404159095932}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,563] Trial 84 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0033636079239750117, 'C': 0.08943798861811075}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,589] Trial 85 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.020857874841531187, 'C': 0.21107053416486576}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,621] Trial 86 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0020401798480271386, 'C': 0.03286460068156107}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,656] Trial 87 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.00789311077851542, 'C': 0.35169964984501134}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,685] Trial 88 finished with value: 0.9649122807017544 and parameters: {'learning_rate': 0.005237010268358667, 'C': 0.014970389682269044}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,719] Trial 89 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0005701458907645441, 'C': 0.1455066518407698}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,755] Trial 90 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.016726550771264417, 'C': 0.05430962016852362}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,776] Trial 91 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0038022234092354723, 'C': 0.0780359662285452}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,819] Trial 92 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0029310037212975652, 'C': 0.022714702216514223}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,850] Trial 93 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.005356554770214249, 'C': 0.11021879367507696}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,882] Trial 94 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.012552103174403934, 'C': 0.17218428927644783}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,913] Trial 95 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.009576535645482918, 'C': 0.035502684891352936}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,942] Trial 96 finished with value: 0.9035087719298246 and parameters: {'learning_rate': 0.002084535607556005, 'C': 0.0013432292583298237}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:55,976] Trial 97 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.006617065843085352, 'C': 0.2678485233520664}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:56,010] Trial 98 finished with value: 0.6228070175438597 and parameters: {'learning_rate': 0.000907658452103256, 'C': 3.7668895560687274e-05}. Best is trial 7 with value: 0.9824561403508771.\n",
      "[I 2024-09-17 11:33:56,039] Trial 99 finished with value: 0.9824561403508771 and parameters: {'learning_rate': 0.0013574238279990783, 'C': 0.04468251513216659}. Best is trial 7 with value: 0.9824561403508771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.008006905143994053, 'C': 0.07777173914815366}\n",
      "Best accuracy:  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar un dataset de ejemplo\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la función objetivo\n",
    "def objective(trial):\n",
    "    # Sugerir hiperparámetros para optimizar\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)  # Tasa de aprendizaje\n",
    "    C = trial.suggest_float('C', 1e-5, 10.0, log=True)  # Parámetro de regularización\n",
    "    \n",
    "    # Preprocesar los datos (escalado)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "    # Definir el modelo con los hiperparámetros sugeridos\n",
    "    model = LogisticRegression(C=C, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de validación\n",
    "    y_pred = model.predict(X_valid_scaled)\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "    # Retornar la métrica que queremos optimizar (en este caso, la precisión)\n",
    "    return accuracy\n",
    "\n",
    "# Crear el estudio de Optuna y realizar la optimización\n",
    "study = optuna.create_study(direction=\"maximize\")  # Optimizamos para maximizar la precisión\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best accuracy: \", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-17 11:41:35,260] A new study created in memory with name: no-name-82ce096b-19e4-4638-9f31-57a1dabc3faa\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:36,030] Trial 0 finished with value: 16.607093811035156 and parameters: {'patch_len': 60, 'hidden_size': 79, 'learning_rate': 6.078138422979291e-05}. Best is trial 0 with value: 16.607093811035156.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:36,487] Trial 1 finished with value: 16.639289259910583 and parameters: {'patch_len': 20, 'hidden_size': 100, 'learning_rate': 0.005758967690826906}. Best is trial 0 with value: 16.607093811035156.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:36,947] Trial 2 finished with value: 15.654653310775757 and parameters: {'patch_len': 29, 'hidden_size': 118, 'learning_rate': 0.0010099809854228778}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:37,395] Trial 3 finished with value: 16.818372905254364 and parameters: {'patch_len': 30, 'hidden_size': 72, 'learning_rate': 0.0016398241117944767}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:37,842] Trial 4 finished with value: 15.996454656124115 and parameters: {'patch_len': 36, 'hidden_size': 52, 'learning_rate': 0.0004021989027606967}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:38,287] Trial 5 finished with value: 18.696370720863342 and parameters: {'patch_len': 64, 'hidden_size': 32, 'learning_rate': 0.00693377192289322}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:38,752] Trial 6 finished with value: 16.150973737239838 and parameters: {'patch_len': 62, 'hidden_size': 73, 'learning_rate': 0.0001792411094956933}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:39,446] Trial 7 finished with value: 15.83184003829956 and parameters: {'patch_len': 53, 'hidden_size': 38, 'learning_rate': 0.005697359601858315}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:40,204] Trial 8 finished with value: 15.865767002105713 and parameters: {'patch_len': 39, 'hidden_size': 117, 'learning_rate': 0.0037642120896572125}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:40,648] Trial 9 finished with value: 17.339305579662323 and parameters: {'patch_len': 27, 'hidden_size': 43, 'learning_rate': 0.0006850503440104992}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:41,324] Trial 10 finished with value: 16.23852550983429 and parameters: {'patch_len': 47, 'hidden_size': 124, 'learning_rate': 2.5021873456551925e-05}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:41,831] Trial 11 finished with value: 16.558226943016052 and parameters: {'patch_len': 50, 'hidden_size': 16, 'learning_rate': 0.0015574909588212383}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:42,292] Trial 12 finished with value: 16.418498754501343 and parameters: {'patch_len': 48, 'hidden_size': 97, 'learning_rate': 0.0014628628657812265}. Best is trial 2 with value: 15.654653310775757.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:42,747] Trial 13 finished with value: 15.441426634788513 and parameters: {'patch_len': 16, 'hidden_size': 56, 'learning_rate': 0.00935591813594946}. Best is trial 13 with value: 15.441426634788513.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:43,227] Trial 14 finished with value: 16.702769696712494 and parameters: {'patch_len': 16, 'hidden_size': 61, 'learning_rate': 0.00014997271988461308}. Best is trial 13 with value: 15.441426634788513.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:44,032] Trial 15 finished with value: 26.2477844953537 and parameters: {'patch_len': 23, 'hidden_size': 93, 'learning_rate': 1.1661734312387496e-05}. Best is trial 13 with value: 15.441426634788513.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:44,624] Trial 16 finished with value: 15.605267882347107 and parameters: {'patch_len': 33, 'hidden_size': 112, 'learning_rate': 0.0026504908423049356}. Best is trial 13 with value: 15.441426634788513.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:45,645] Trial 17 finished with value: 16.16274267435074 and parameters: {'patch_len': 35, 'hidden_size': 86, 'learning_rate': 0.009841324417647226}. Best is trial 13 with value: 15.441426634788513.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:46,209] Trial 18 finished with value: 16.042128205299377 and parameters: {'patch_len': 17, 'hidden_size': 108, 'learning_rate': 0.0025644610958248217}. Best is trial 13 with value: 15.441426634788513.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:46,682] Trial 19 finished with value: 15.3440922498703 and parameters: {'patch_len': 24, 'hidden_size': 60, 'learning_rate': 0.0033506627080478915}. Best is trial 19 with value: 15.3440922498703.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:47,135] Trial 20 finished with value: 16.471455991268158 and parameters: {'patch_len': 23, 'hidden_size': 59, 'learning_rate': 0.0035953475443821514}. Best is trial 19 with value: 15.3440922498703.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:47,590] Trial 21 finished with value: 16.65477156639099 and parameters: {'patch_len': 24, 'hidden_size': 59, 'learning_rate': 0.009747360776574008}. Best is trial 19 with value: 15.3440922498703.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:48,043] Trial 22 finished with value: 15.159299969673157 and parameters: {'patch_len': 32, 'hidden_size': 66, 'learning_rate': 0.003124561409572657}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:48,489] Trial 23 finished with value: 16.01799726486206 and parameters: {'patch_len': 20, 'hidden_size': 50, 'learning_rate': 0.0005606974483833693}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:48,970] Trial 24 finished with value: 15.234673023223877 and parameters: {'patch_len': 41, 'hidden_size': 66, 'learning_rate': 0.004042218666726582}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:49,427] Trial 25 finished with value: 16.1335751414299 and parameters: {'patch_len': 42, 'hidden_size': 66, 'learning_rate': 0.00023685460085243177}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:49,900] Trial 26 finished with value: 16.143901646137238 and parameters: {'patch_len': 41, 'hidden_size': 78, 'learning_rate': 0.000919910911221971}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:51,056] Trial 27 finished with value: 15.578114986419678 and parameters: {'patch_len': 33, 'hidden_size': 84, 'learning_rate': 0.003420445106999527}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:52,186] Trial 28 finished with value: 15.86698442697525 and parameters: {'patch_len': 45, 'hidden_size': 68, 'learning_rate': 0.002397721542545495}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:52,616] Trial 29 finished with value: 16.29374325275421 and parameters: {'patch_len': 27, 'hidden_size': 28, 'learning_rate': 8.190903492968522e-05}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:53,057] Trial 30 finished with value: 16.032935678958893 and parameters: {'patch_len': 55, 'hidden_size': 46, 'learning_rate': 0.00040102200118773596}. Best is trial 22 with value: 15.159299969673157.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:53,498] Trial 31 finished with value: 15.129777789115906 and parameters: {'patch_len': 19, 'hidden_size': 55, 'learning_rate': 0.0040124225311043375}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:53,941] Trial 32 finished with value: 17.353555560112 and parameters: {'patch_len': 20, 'hidden_size': 70, 'learning_rate': 0.006265985900779872}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:54,382] Trial 33 finished with value: 15.865913033485413 and parameters: {'patch_len': 30, 'hidden_size': 65, 'learning_rate': 0.004803601354283918}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:54,832] Trial 34 finished with value: 15.884719789028168 and parameters: {'patch_len': 38, 'hidden_size': 78, 'learning_rate': 0.0017056411477326977}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:55,284] Trial 35 finished with value: 16.14946722984314 and parameters: {'patch_len': 26, 'hidden_size': 50, 'learning_rate': 0.0010587742959254933}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:55,727] Trial 36 finished with value: 15.279443562030792 and parameters: {'patch_len': 34, 'hidden_size': 41, 'learning_rate': 0.0047012423341149965}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:56,440] Trial 37 finished with value: 15.714094042778015 and parameters: {'patch_len': 43, 'hidden_size': 36, 'learning_rate': 0.002095025782644972}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:57,156] Trial 38 finished with value: 16.219715774059296 and parameters: {'patch_len': 33, 'hidden_size': 25, 'learning_rate': 0.005074361677783098}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:57,909] Trial 39 finished with value: 16.402500867843628 and parameters: {'patch_len': 37, 'hidden_size': 42, 'learning_rate': 0.0010785650448854396}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:58,706] Trial 40 finished with value: 16.18955284357071 and parameters: {'patch_len': 57, 'hidden_size': 54, 'learning_rate': 0.006952447946428803}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:59,175] Trial 41 finished with value: 16.159607470035553 and parameters: {'patch_len': 30, 'hidden_size': 74, 'learning_rate': 0.003728972400069332}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:41:59,809] Trial 42 finished with value: 15.73871225118637 and parameters: {'patch_len': 34, 'hidden_size': 61, 'learning_rate': 0.0047683635060733415}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:00,459] Trial 43 finished with value: 15.967154502868652 and parameters: {'patch_len': 28, 'hidden_size': 46, 'learning_rate': 0.002897452803308722}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:00,923] Trial 44 finished with value: 15.818065404891968 and parameters: {'patch_len': 19, 'hidden_size': 54, 'learning_rate': 0.0018796358138998322}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:01,385] Trial 45 finished with value: 15.259000658988953 and parameters: {'patch_len': 25, 'hidden_size': 35, 'learning_rate': 0.00767833576853568}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:01,812] Trial 46 finished with value: 17.768193781375885 and parameters: {'patch_len': 30, 'hidden_size': 18, 'learning_rate': 0.006453770933545413}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:02,268] Trial 47 finished with value: 17.095062136650085 and parameters: {'patch_len': 36, 'hidden_size': 36, 'learning_rate': 0.007472284869603698}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:02,729] Trial 48 finished with value: 16.208194196224213 and parameters: {'patch_len': 39, 'hidden_size': 31, 'learning_rate': 0.0013031657050463768}. Best is trial 31 with value: 15.129777789115906.\n",
      "/var/folders/dt/cxyz36h16ydfv1yg6n6v5fqm0000gn/T/ipykernel_630/650021108.py:99: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
      "[I 2024-09-17 11:42:03,187] Trial 49 finished with value: 15.738821029663086 and parameters: {'patch_len': 31, 'hidden_size': 41, 'learning_rate': 0.004512160345646761}. Best is trial 31 with value: 15.129777789115906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'patch_len': 19, 'hidden_size': 55, 'learning_rate': 0.0040124225311043375}\n",
      "Best validation SMAPE:  15.129777789115906\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Simulación de datos de series temporales financieras\n",
    "def generate_synthetic_data(n_series=100, n_timesteps=120, noise=0.1):\n",
    "    \"\"\"\n",
    "    Genera datos sintéticos de series temporales para simular datos financieros.\n",
    "    Cada serie es una señal sinusoidal con un poco de ruido.\n",
    "    \"\"\"\n",
    "    X = np.zeros((n_series, n_timesteps))\n",
    "    y = np.zeros((n_series,))\n",
    "    \n",
    "    for i in range(n_series):\n",
    "        t = np.arange(0, n_timesteps)\n",
    "        X[i, :] = np.sin(2 * np.pi * t / 25) + noise * np.random.randn(n_timesteps)\n",
    "        y[i] = X[i, -1] + noise * np.random.randn()  # Predecir el último valor de la serie\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generar los datos de entrenamiento y validación\n",
    "X_train, y_train = generate_synthetic_data(n_series=800, n_timesteps=104)\n",
    "X_valid, y_valid = generate_synthetic_data(n_series=200, n_timesteps=104)\n",
    "\n",
    "# Convertir los datos a tensores\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid, dtype=torch.float32)\n",
    "\n",
    "# Crear DataLoader para alimentar los datos al modelo\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(TensorDataset(X_valid_tensor, y_valid_tensor), batch_size=32)\n",
    "\n",
    "# Definir el modelo PatchTST (simplificado)\n",
    "class PatchTST(nn.Module):\n",
    "    def __init__(self, input_size, patch_len, hidden_size):\n",
    "        super(PatchTST, self).__init__()\n",
    "        self.patch_len = patch_len\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Definir una red simple con capas lineales\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Aplicar la red\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Función para calcular MAPE\n",
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Función para calcular sMAPE\n",
    "def sMAPE(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Función para entrenar el modelo\n",
    "def train_model(model, optimizer, train_loader, valid_loader, n_epochs=10):\n",
    "    criterion = nn.MSELoss()  # Usamos el MSE como métrica de error\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluación del modelo en el conjunto de validación\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in valid_loader:\n",
    "            output = model(X_batch)\n",
    "            preds.append(output.squeeze().numpy())\n",
    "            targets.append(y_batch.numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    \n",
    "    mse = mean_squared_error(targets, preds)\n",
    "    mape = MAPE(targets, preds)\n",
    "    smape = sMAPE(targets, preds)\n",
    "    \n",
    "    return mse, mape, smape\n",
    "\n",
    "# Función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Sugerir hiperparámetros\n",
    "    patch_len = trial.suggest_int('patch_len', 16, 64)  # Longitud del parche\n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 128)  # Tamaño de la capa oculta\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Tasa de aprendizaje\n",
    "\n",
    "    # Crear el modelo PatchTST con los hiperparámetros sugeridos\n",
    "    model = PatchTST(input_size=104, patch_len=patch_len, hidden_size=hidden_size)\n",
    "    \n",
    "    # Optimizador\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Entrenar el modelo y obtener el MSE, MAPE y sMAPE en el conjunto de validación\n",
    "    mse, mape, smape = train_model(model, optimizer, train_loader, valid_loader, n_epochs=10)\n",
    "    \n",
    "    # Optimizamos el MSE, pero también podrías optimizar MAPE o sMAPE\n",
    "    return smape\n",
    "\n",
    "# Ejecutar la optimización con Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")  # Queremos minimizar el MSE\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best validation SMAPE: \", study.best_value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
